{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Data Cleaning\n",
    "\n",
    "**Main Objective:**  \n",
    "In this notebook we inspect and clean missing or duplicate values in the three main datasets:\n",
    "\n",
    "1. **Raw CVs** (original, unstructured CV text)  \n",
    "2. **Parsed Skills** (the `cv_skills` DataFrame that feeds the matcher)  \n",
    "3. **Matcher Results** (output CSV from the matching algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "import re\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "from hiring_cv_bias.cleaning.common import (\n",
    "    filter_out_candidate_ids,\n",
    "    find_dropped_skill_rows,\n",
    "    inspect_missing,\n",
    ")\n",
    "from hiring_cv_bias.cleaning.raw_cv import (\n",
    "    add_length_column,\n",
    "    assess_translation_completeness,\n",
    "    detect_corrupted_cvs,\n",
    "    detect_repetitive_cvs,\n",
    "    detect_vocab_sparsity,\n",
    "    filter_placeholder_tails,\n",
    "    find_and_print_short_cvs,\n",
    "    is_this_language,\n",
    "    plot_length_histogram,\n",
    ")\n",
    "from hiring_cv_bias.config import (\n",
    "    CANDIDATE_CVS_TRANSLATED_PATH,\n",
    "    PARSED_DATA_PATH,\n",
    "    REVERSE_MATCHING_PATH,\n",
    ")\n",
    "from hiring_cv_bias.utils import load_data, load_excel_sheets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## 1. **Raw CVs** Cleaning Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### 1. Schema & Load \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "   - Define expected columns and data types (`CANDIDATE_ID: UInt64`, `CV_text_anon: String`, `Translated_CV: String`)  \n",
    "   - Load CSV into Polars DataFrame, verify row count matches the number of uniques Candidate IDs.\n",
    "   - Check for duplicate `CANDIDATE_ID` entries -> no duplicates found. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_cv = load_data(CANDIDATE_CVS_TRANSLATED_PATH)\n",
    "print(\"DataFrame schema:\", raw_cv.schema)\n",
    "print(f\"Loaded: {raw_cv.height} CVs\")\n",
    "\n",
    "################\n",
    "\n",
    "total_rows = raw_cv.height\n",
    "unique_ids = raw_cv.select(pl.col(\"CANDIDATE_ID\")).unique().height\n",
    "print(f\"Unique CANDIDATE_ID: {unique_ids}\")\n",
    "print(\"\\nSample rows:\")\n",
    "print(raw_cv.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### 2. Missing Value Inspection \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "   - Count nulls per column (`null_count()`), compute percentage of missing values and report any columns with > 0% missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_stats = inspect_missing(raw_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### 3. Short- or Empty-CV Detection  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "Under this step we will:\n",
    "\n",
    "1. **Empty / Whitespace-Only/ Very Short Text**  \n",
    "   - Filter out any records where `CV_text_anon` is below a chosen threshold (e.g. 300 characters), showing their IDs and snippets for manual review.\n",
    "\n",
    "2. **High Repetition / Low Structure**  \n",
    "   - Split each CV into non-empty lines, count `n_lines` and `unique_lines`.  \n",
    "   - Compute `repetition_ratio = 1 − (unique_lines / n_lines)`.  \n",
    "   - Flag and drop any CVs with `repetition_ratio` above a threshold (e.g. > 0.7).\n",
    "\n",
    "These checks ensure we remove any CVs that are dominated by boilerplate before proceeding with further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_length_histogram(raw_cv, text_col=\"CV_text_anon\", bin_size=300, max_bin=3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "Remove Empty / Whitespace-Only/ Very Short Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_cv = add_length_column(raw_cv, text_col=\"CV_text_anon\", length_col=\"len_anon\")\n",
    "\n",
    "\n",
    "too_short_df = find_and_print_short_cvs(\n",
    "    raw_cv,\n",
    "    length_col=\"len_anon\",\n",
    "    threshold=300,\n",
    "    id_col=\"CANDIDATE_ID\",\n",
    "    text_col=\"CV_text_anon\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_cvs_ids = too_short_df.select(pl.col(\"CANDIDATE_ID\")).to_series().to_list()\n",
    "raw_cv_cleaned = filter_out_candidate_ids(\n",
    "    raw_cv, short_cvs_ids, df_name=\"CVs\", description=\"under 300 characters\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "Remove High Repetition / Low Structure CVs  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "repetitive_cvs = detect_repetitive_cvs(\n",
    "    raw_cv_cleaned, text_col=\"CV_text_anon\", max_repetition=0.5\n",
    ")\n",
    "print(f\"Found {repetitive_cvs.height} repetitive CVs:\")\n",
    "print(repetitive_cvs.select([\"CANDIDATE_ID\", \"n_lines\", \"repetition_ratio\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "repetitive_cvs_ids = repetitive_cvs.select(pl.col(\"CANDIDATE_ID\")).to_series().to_list()\n",
    "raw_cv_cleaned = filter_out_candidate_ids(\n",
    "    raw_cv_cleaned, repetitive_cvs_ids, df_name=\"CVs\", description=\"repetitive CVs\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### 4. Text Quality Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "To further ensure we filter out “bad” or malformed CVs, we will perform:\n",
    "\n",
    "1. **Token & Vocabulary Richness**  \n",
    "   - Calculate the unique words / total words ratio to measure lexical variety.\n",
    "   - Filter out CVs with very low number of unique words (e.g < 20) or very low ratio (e.g. < 0.2).\n",
    "\n",
    "2. **Detect Redacted‐Placeholder Tails**\n",
    "   - Flag any CV whose text ends with a long run of the same character (e.g. “XXXXXXXXXX…”), seen after manual inspection. These indicate fully redacted templates with no usable content and should be excluded.\n",
    "\n",
    "3. **Detect Garbled/Corrupted CVs**\n",
    "   - Compute the fraction of “unusual” characters (outside printable ASCII, Latin-1, or standard punctuation) in each CV. Flag and remove any CV where this fraction exceeds a small threshold (e.g. 3%), catching heavily garbled or control-code–laden documents.\n",
    "\n",
    "\n",
    "These additional checks will help us catch CVs that are too short, overly repetitive, structurally invalid, or otherwise unfit for reliable parsing and downstream analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "**Token & Vocabulary Richness**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_cvs = detect_vocab_sparsity(\n",
    "    raw_cv_cleaned, text_col=\"CV_text_anon\", min_words=30, min_ttr=0.3\n",
    ")\n",
    "\n",
    "print(f\"CVs to discard based on vocabulary sparsity: {sparse_cvs.height}\")\n",
    "print(\n",
    "    sparse_cvs.select([\"CANDIDATE_ID\", \"total_words\", \"unique_words\", \"ttr\"]).sort(\n",
    "        pl.col(\"ttr\"), descending=False\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_ids = sparse_cvs.select(pl.col(\"CANDIDATE_ID\")).to_series().to_list()\n",
    "raw_cv_cleaned = filter_out_candidate_ids(\n",
    "    raw_cv_cleaned, sparse_ids, df_name=\"CVs\", description=\"low lexical variety\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "**Detect Redacted‐Placeholder Tails**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "placeholder_cvs = filter_placeholder_tails(\n",
    "    raw_cv_cleaned, text_col=\"CV_text_anon\", char=\"X\", min_run=20\n",
    ")\n",
    "print(f\"Found {placeholder_cvs.height} CVs with trailing X placeholders:\")\n",
    "print(placeholder_cvs.select([\"CANDIDATE_ID\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "placeholder_ids = placeholder_cvs.select(pl.col(\"CANDIDATE_ID\")).to_series().to_list()\n",
    "raw_cv_cleaned = filter_out_candidate_ids(\n",
    "    raw_cv_cleaned,\n",
    "    placeholder_ids,\n",
    "    df_name=\"CVs\",\n",
    "    description=\"trailing X placeholders\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "**Detect Garbled/Corrupted CVs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted_cvs = detect_corrupted_cvs(\n",
    "    raw_cv_cleaned, text_col=\"CV_text_anon\", max_unusual_frac=0.02\n",
    ")\n",
    "print(f\"Corrupted CVs to discard: {corrupted_cvs.height}\")\n",
    "print(\n",
    "    corrupted_cvs.select([\"CANDIDATE_ID\", \"unusual_frac\"]).sort(\n",
    "        \"unusual_frac\", descending=True\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted_ids = corrupted_cvs.select(pl.col(\"CANDIDATE_ID\")).to_series().to_list()\n",
    "raw_cv_cleaned = filter_out_candidate_ids(\n",
    "    raw_cv_cleaned, corrupted_ids, df_name=\"CVs\", description=\"corrupted symbols\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "### 5. **Translation Completeness**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "- **Filter Out Poor Translations**  \n",
    "  Compute len_ratio = `len(Translated_CV) / len(CV_text_anon)` and flag any CV with <br>\n",
    "  `len_ratio < 0.7` (e.g. single-character outputs or garbled text) or an empty/missing translation. <br>\n",
    "  \n",
    "Since these cases are very rare, we drop them outright instead of attempting a fallback or re-translation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_stats_df = assess_translation_completeness(raw_cv_cleaned)\n",
    "print(\n",
    "    translation_stats_df.filter(pl.col(\"len_ratio\") < 0.7)\n",
    "    .select([\"CANDIDATE_ID\", \"orig_len\", \"trans_len\", \"len_ratio\"])\n",
    "    .sort(\"len_ratio\", descending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_translation_ids = (\n",
    "    translation_stats_df.filter(pl.col(\"len_ratio\") < 0.7)\n",
    "    .select(\"CANDIDATE_ID\")\n",
    "    .to_series()\n",
    "    .to_list()\n",
    ")\n",
    "raw_cv_cleaned = filter_out_candidate_ids(\n",
    "    raw_cv_cleaned,\n",
    "    low_translation_ids,\n",
    "    df_name=\"CVs\",\n",
    "    description=\"low translation completeness\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "We ran our language‐detection check on the **Italian** `CV_text_anon` and found **155** records flagged as “not Italian.” \n",
    "\n",
    "**Since our downstream analysis relies exclusively on the English translations**, we’re not going to drop these files. Instead, we will now verify that the **`Translated_CV`** column truly contains English text before proceeding with bias and skill‐extraction analyses.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_italian_df = (\n",
    "    raw_cv_cleaned.with_columns(\n",
    "        [\n",
    "            pl.col(\"CV_text_anon\")\n",
    "            .map_elements(\n",
    "                lambda s, *_: not is_this_language(s or \"\", \"it\"),\n",
    "                return_dtype=pl.Boolean,\n",
    "            )\n",
    "            .alias(\"not_italian\")\n",
    "        ]\n",
    "    )\n",
    "    .select([\"CANDIDATE_ID\", \"CV_text_anon\", \"not_italian\"])\n",
    "    .filter(pl.col(\"not_italian\"))\n",
    ")\n",
    "print(f\"Found {not_italian_df.height} CVs not in Italian.\")\n",
    "print(not_italian_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sample CVs not in Italian:\")\n",
    "print(not_italian_df.sample(1)[\"CV_text_anon\"].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_english_df = (\n",
    "    raw_cv_cleaned.with_columns(\n",
    "        [\n",
    "            pl.col(\"Translated_CV\")\n",
    "            .map_elements(\n",
    "                lambda s, *_: not is_this_language(s or \"\", \"en\"),\n",
    "                return_dtype=pl.Boolean,\n",
    "            )\n",
    "            .alias(\"not_english\")\n",
    "        ]\n",
    "    )\n",
    "    .select([\"CANDIDATE_ID\", \"Translated_CV\", \"not_english\"])\n",
    "    .filter(pl.col(\"not_english\"))\n",
    ")\n",
    "print(f\"Found {not_english_df.height} CVs not in English.\")\n",
    "print(not_english_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sample CVs not in English:\")\n",
    "print(not_english_df.sample(1)[\"Translated_CV\"].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "We ran our check on the **Translated_CV** column and found only **16** records flagged as non-English. After a manual review, we discovered that these CVs are indeed written in English but include many Italian place names, addresses and organization titles which skew the language detector’s statistics. Since the underlying text is English and these cases are few, we will **not** drop them.\n",
    "\n",
    "> **Note:** going forward, all regex or pattern-based quality checks should be applied **only** to the **English** `Translated_CV` field.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "### 6. **Handling Empty CV Records** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "During our inspection we found many corrupted CVs. <br>\n",
    "In each dedicated section, to ensure data quality and consistency across all our analyses, we will:\n",
    "\n",
    "1. **Exclude their parsed skills**  \n",
    "   Filter out any rows in our parsed skills DataFrame (`cv_skills`) corresponding to those same `CANDIDATE_ID`s.\n",
    "\n",
    "2. **Omit their entries in the Reverse Matching results**  \n",
    "   Drop records in the Reverse Matching dataset (`ReverseMatching.xlsx`) for those candidate IDs.\n",
    "\n",
    "This cleanup step prevents entirely missing CVs from biasing our skill‐extraction and matching analyses. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "## 2. **Parsed Skills** (the `cv_skills` DataFrame that feeds the matcher)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "### 1. Schema & Load "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_cv = load_data(CANDIDATE_CVS_TRANSLATED_PATH)\n",
    "raw_skills = load_data(PARSED_DATA_PATH)\n",
    "print(\"DataFrame schema:\", raw_skills.schema)\n",
    "print(f\"Loaded: {raw_skills.height} Skills\")\n",
    "\n",
    "################\n",
    "\n",
    "total_rows = raw_skills.height\n",
    "unique_ids = raw_skills.select(pl.col(\"CANDIDATE_ID\")).unique().height\n",
    "print(f\"Unique CANDIDATE_ID: {unique_ids}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "Exclude parsed skills of the candidates with corrupted CVs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_cv_ids = raw_cv.select(pl.col(\"CANDIDATE_ID\")).to_series().to_list()\n",
    "print(\"Number of CVs loaded ->\", len(raw_cv_ids))\n",
    "\n",
    "raw_cv_cleaned_ids = raw_cv_cleaned.select(pl.col(\"CANDIDATE_ID\")).to_series().to_list()\n",
    "print(\n",
    "    \"Number of CVs kept after cleaning ->\",\n",
    "    len(raw_cv_cleaned_ids),\n",
    ")\n",
    "\n",
    "raw_cv_deleted_ids = (\n",
    "    raw_cv.filter(~pl.col(\"CANDIDATE_ID\").is_in(raw_cv_cleaned_ids))\n",
    "    .select(pl.col(\"CANDIDATE_ID\"))\n",
    "    .to_series()\n",
    "    .to_list()\n",
    ")\n",
    "print(\n",
    "    \"Number of CVs deleted ->\",\n",
    "    len(raw_cv_deleted_ids),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_skills_cleaned = filter_out_candidate_ids(\n",
    "    raw_skills, raw_cv_deleted_ids, df_name=\"Skills\", description=\"CVs deleted\"\n",
    ")\n",
    "\n",
    "##################\n",
    "\n",
    "# Sanity check on the new number of unique candidate IDs.\n",
    "\n",
    "total_rows = raw_skills_cleaned.height\n",
    "unique_ids = raw_skills_cleaned.select(pl.col(\"CANDIDATE_ID\")).unique().height\n",
    "print(f\"Unique CANDIDATE_ID: {unique_ids}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "### 2. Missing Value Inspection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_skills = inspect_missing(raw_skills_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "Inspecting missing values we've found that 82 rows are missing a `Skill` value. Diving into the data, we see that these rows are all associated with the value `DRIVERSLIC` in the `Skill_Type` column. <br>\n",
    "This indicates that these rows are likely placeholders for driver license information, which is however useful to our analysis. <br>\n",
    "We will **not** drop these rows from the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "**Remove Missing or Null Skills**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_rows = raw_skills_cleaned.filter(\n",
    "    pl.col(\"Skill\").is_null() & (pl.col(\"Skill_Type\") != \"DRIVERSLIC\")\n",
    ")\n",
    "print(f\"Found {invalid_rows.height} rows with missing Skill (excluding DRIVERSLIC):\")\n",
    "print(invalid_rows)\n",
    "\n",
    "##################\n",
    "\n",
    "raw_skills_cleaned = raw_skills_cleaned.filter(\n",
    "    ~(pl.col(\"Skill\").is_null() & (pl.col(\"Skill_Type\") != \"DRIVERSLIC\"))\n",
    ")\n",
    "print(f\"After dropping invalid rows, {raw_skills_cleaned.height} skill records remain.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "### 3. Find exact duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_before = raw_skills_cleaned.height\n",
    "unique_before = raw_skills_cleaned.unique(subset=[\"CANDIDATE_ID\", \"Skill\"]).height\n",
    "\n",
    "print(f\"Total rows: {total_before}\")\n",
    "print(f\"Unique (ID, Skill, Skill_Type): {unique_before}\")\n",
    "\n",
    "##################\n",
    "\n",
    "if total_before != unique_before:\n",
    "    raw_skills_cleaned = raw_skills_cleaned.unique(subset=[\"CANDIDATE_ID\", \"Skill\"])\n",
    "    print(f\"Dropped {total_before - unique_before} duplicates.\")\n",
    "else:\n",
    "    print(\"No duplicates found—skipping deduplication.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "### 4. Validate Skill Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "- Ensure Skill_Type only takes one of your known categories\n",
    "  (`IT_Skill`, `Job_title`, `Language_Skill`, `Professional_Skill`, `DRIVERSLIC`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_TYPES = [\n",
    "    \"IT_Skill\",\n",
    "    \"Job_title\",\n",
    "    \"Language_Skill\",\n",
    "    \"Professional_Skill\",\n",
    "    \"DRIVERSLIC\",\n",
    "]\n",
    "\n",
    "all_types = raw_skills_cleaned.select(\"Skill_Type\").unique().to_series().to_list()\n",
    "invalid_types = [t for t in all_types if t not in VALID_TYPES]\n",
    "\n",
    "##############\n",
    "\n",
    "if invalid_types:\n",
    "    print(\"Found invalid Skill_Type values:\")\n",
    "    for t in invalid_types:\n",
    "        print(\"  -\", t)\n",
    "else:\n",
    "    print(\"All Skill_Type values are valid.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "### 5. Filter Out Garbage Skill Tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {},
   "source": [
    "   - Drop any `Skill` entries that are obviously malformed (e.g. length < 2 or > 100, only punctuation or digits).  \n",
    "   - Optionally remove entries matching placeholder patterns (like a long run of `X`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_skills = raw_skills_cleaned\n",
    "placeholder_pattern = re.compile(r\"X{5,}\")\n",
    "\n",
    "# apply the garbage‐filter again to get the “cleaned” set\n",
    "cleaned_skills = original_skills.filter(\n",
    "    # length 2–100\n",
    "    (\n",
    "        pl.col(\"Skill\").map_elements(lambda s, *_: len(s or \"\"), return_dtype=pl.Int64)\n",
    "        >= 2\n",
    "    )\n",
    "    & (\n",
    "        pl.col(\"Skill\").map_elements(lambda s, *_: len(s or \"\"), return_dtype=pl.Int64)\n",
    "        <= 100\n",
    "    )\n",
    "    &\n",
    "    # contains at least one letter\n",
    "    pl.col(\"Skill\").str.contains(r\"[A-Za-z]\", literal=False)\n",
    "    &\n",
    "    # not placeholder\n",
    "    pl.col(\"Skill\").map_elements(\n",
    "        lambda s, *_: not bool(placeholder_pattern.search(s or \"\")),\n",
    "        return_dtype=pl.Boolean,\n",
    "    )\n",
    ")\n",
    "\n",
    "dropped_skills = original_skills.join(\n",
    "    cleaned_skills.select([\"CANDIDATE_ID\", \"Skill\", \"Skill_Type\"]),\n",
    "    on=[\"CANDIDATE_ID\", \"Skill\", \"Skill_Type\"],\n",
    "    how=\"anti\",\n",
    ")\n",
    "\n",
    "print(f\"Dropped {dropped_skills.height} skill rows:\")\n",
    "print(dropped_skills.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_skills = find_dropped_skill_rows(raw_skills)\n",
    "print(f\"Dropped {dropped_skills.height} skill rows:\")\n",
    "print(dropped_skills.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_skills.filter(pl.col(\"Skill_Type\") == \"DRIVERSLIC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "All the dropped_skills would be DRIVERSLIC, so we will **not** drop any rows from the skills, as previously discussed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63",
   "metadata": {},
   "source": [
    "## 3. **Matcher Results** (output CSV from the matching algorithm) -> To be discussed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64",
   "metadata": {},
   "source": [
    "To be discussed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "reversed_skills_matching_dict = load_excel_sheets(\n",
    "    REVERSE_MATCHING_PATH, sheets=[\"Candidates\"]\n",
    ")\n",
    "reversed_skills_matching = reversed_skills_matching_dict[\"Candidates\"]\n",
    "\n",
    "print(\"DataFrame schema:\", reversed_skills_matching.schema)\n",
    "print(f\"Loaded: {reversed_skills_matching.height} candidates\")\n",
    "\n",
    "################\n",
    "\n",
    "total_rows = reversed_skills_matching.height\n",
    "unique_ids = reversed_skills_matching.select(pl.col(\"CANDIDATE_ID\")).unique().height\n",
    "print(f\"Unique CANDIDATE_ID: {unique_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_reversed_skills = inspect_missing(reversed_skills_matching)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67",
   "metadata": {},
   "source": [
    "## Exporting the Cleaned Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "- **Export the cleaned CVs**, the **cleaned parsed skills**, the **cleaned matcher result** to a **new** CSV file, ensuring the schema and data types are preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_cv_cleaned.write_csv(\n",
    "    \"../data/Adecco_Dataset_cleaned/CV_translated_cleaned.csv\", separator=\";\"\n",
    ")\n",
    "raw_skills_cleaned.write_csv(\n",
    "    \"../data/Adecco_Dataset_cleaned/Skills_cleaned.csv\", separator=\";\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "rise": {
   "theme": "moon"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
